{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e4e5436d29092d",
   "metadata": {},
   "source": [
    "# დამატებითი მასალა:\n",
    "- ვიდეოები:\n",
    "    - [How large language models work, a visual intro to transformers | Chapter 5, Deep Learning](https://www.youtube.com/watch?v=wjZofJX0v4M&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=5&ab_channel=3Blue1Brown)\n",
    "    - [Attention in transformers, visually explained | Chapter 6, Deep Learning](https://www.youtube.com/watch?v=eMlx5fFNoYc&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=6&ab_channel=3Blue1Brown)\n",
    "    - [How might LLMs store facts | Chapter 7, Deep Learning](https://www.youtube.com/watch?v=9-Jl0dxWQs8&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=7&ab_channel=3Blue1Brown)\n",
    "    - [Transformer Neural Networks Derived from Scratch | Algorithmic Simplicity](https://www.youtube.com/watch?v=kWLed8o5M2Y)\n",
    "    - [AI can't cross this line and we don't know why | Welch Labs](https://www.youtube.com/watch?v=5eqRuVp65eY&ab_channel=WelchLabs)\n",
    "- ბლოგები:\n",
    "    - [NLP course by Lena Voita (Transformers)](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)\n",
    "    - [Annotated Transformer | MIT](https://nlp.seas.harvard.edu/annotated-transformer/)\n",
    "- ვიზუალიზაცია:\n",
    "    - [Transformer Explained](https://poloclub.github.io/transformer-explainer/)\n",
    "    - [LLM Visualization by Brendan Bycroft](https://bbycroft.net/llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0aa45c",
   "metadata": {},
   "source": [
    "# ენის მოდელირება (Language Modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89232c21",
   "metadata": {},
   "source": [
    "2017 წელს წარდგენილმა ამ ტრანსფორმერებმა მნიშვნელოვნად შეცვალა ბუნებრივი ენის დამუშავების (NLP) სფერო, თუ როგორ ვუდგებით ენობრივ ამოცანებს და რა შედეგებს ველოდებით მათგან.\n",
    "\n",
    "ტრანსფორმერები წარმოადგენენ ნეირონული ქსელის არქიტექტურას, რომელიც ეფუძნება ე.წ. \"ყურადღების მექანიზმს\" (attention mechanism). ეს ტექნიკა საშუალებას აძლევს მოდელს ფოკუსირდეს შემავალი ტექსტის სხვადასხვა ნაწილზე, რაც უზრუნველყოფს კონტექსტის უკეთ გაგებას და ურთიერთკავშირების დამყარებას შორეულ ელემენტებს შორის.\n",
    "\n",
    "ტრანსფორმერების გამოჩენამდე, NLP-ში ძირითადად გამოიყენებოდა რეკურენტული ნეირონული ქსელები (RNN) და LSTM მოდელები. თუმცა, ამ არქიტექტურებს ჰქონდათ შეზღუდვები გრძელი თანმიმდევრობების დამუშავებისას და პარალელიზაციის თვალსაზრისით.\n",
    "\n",
    "ტრანსფორმერებმა გადაჭრეს ეს პრობლემები და ჩაუყარეს საფუძველი ისეთი მძლავრი ენობრივი მოდელების არსებობას, როგორებიცაა BERT, GPT და სხვა. ამ მოდელებმა მნიშვნელოვნად გააუმჯობესეს შედეგები მრავალ NLP ამოცანაში, მათ შორის მანქანურ თარგმანში, ტექსტის კლასიფიკაციაში, სენტიმენტის ანალიზში და ტექსტის გენერაციაში.\n",
    "\n",
    "ტრანსფორმერების გავლენა NLP-ზე სცდება მხოლოდ შედეგების გაუმჯობესებას. მათ შეცვალეს ჩვენი მიდგომა ენის მოდელირების მიმართ, გახადეს შესაძლებელი უზარმაზარი მოდელების შექმნა."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3272a7d8",
   "metadata": {},
   "source": [
    "დასაწყისისთვის, შეგიძლიათ გამოიყენოთ [ტრანსფორმერის ვიზუალიზაცია](https://poloclub.github.io/transformer-explainer/), ჩაწერეთ რაიმე ტექსტი და დააკვირდით თქვენი ტექსტის გაგრძელების რა ვარიანტებს გთავაზობთ მოდელი:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e55dd8d",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <video src=\"images/Transformer Explained.mov\" controls autoplay loop style=\"display: block; margin: 0 auto\" width=600/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a623bb5f97b527",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/wjZofJX0v4M?si=sn7eRvfVcgjVcf5h\" title=\"YouTube video player\" frameborder=\"0\" allowfullscreen></iframe>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8cd527",
   "metadata": {},
   "source": [
    "# Sequence to Sequence ამოცანები"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b247b",
   "metadata": {},
   "source": [
    "Sequence to Sequence ამოცანა შეიძლება განვსაზღვროთ როგორც ფუნქცია f, რომელიც გარდაქმნის შემავალ მიმდევრობას X შესაბამის გამომავალ მიმდევრობაში Y:\n",
    "\n",
    "f: X → Y\n",
    "სადაც:\n",
    "- X = (x₁, x₂, ..., xₙ) არის შემავალი მიმდევრობა (Input Sequence)\n",
    "- Y = (y₁, y₂, ..., yₘ) არის გამომავალი მიმდევრობა (Output Sequence)\n",
    "\n",
    "ყურადღება მიაქციეთ, რომ n და m შეიძლება იყოს განსხვავებული სიგრძის, ანუ შემავალი და გამომავალი მიმდევრობების სიგრძეები შეიძლება არ იყოს ერთმანეთის ტოლი.\n",
    "\n",
    "seq-to-seq ამოცანები შეიძლება შეეხებოდეს, როგორც ტექსტის მიმდევრობებს, ასევე ნებისმიერ სხვა მოდალობას, როგორებიცაა აუდიო სიგნალები, ფოტო, ვიდეო და სხვა. ამ ტიპის ამოცანების მაგალითებია:\n",
    "\n",
    "- მანქანური თარგმანი:\n",
    "    - შემავალი მიმდევრობა: წინადადება ერთ ენაზე\n",
    "    - გამომავალი მიმდევრობა: იგივე წინადადება სხვა ენაზე\n",
    "    - მაგალითი: \"Hello, how are you?\" → \"გამარჯობა, როგორ ხარ?\"\n",
    "\n",
    "- ტექსტის შეჯამება:\n",
    "    - შემავალი მიმდევრობა: გრძელი ტექსტი ან დოკუმენტი\n",
    "    - გამომავალი მიმდევრობა: ტექსტის მოკლე შეჯამება\n",
    "    - მაგალითი: [გრძელი სტატია] → \"სტატია აღწერს კლიმატის ცვლილების გავლენას ოკეანეებზე\"\n",
    "\n",
    "- დიალოგის სისტემები:\n",
    "    - შემავალი მიმდევრობა: მომხმარებლის შეკითხვა ან მოთხოვნა\n",
    "    - გამომავალი მიმდევრობა: სისტემის პასუხი\n",
    "    - მაგალითი: \"რა არის დღეს ამინდის პროგნოზი?\" → \"დღეს მოსალოდნელია მზიანი ამინდი, მაქსიმალური ტემპერატურა 25°C\"\n",
    "\n",
    "- კოდის გენერაცია:\n",
    "    - შემავალი მიმდევრობა: პროგრამის აღწერა ბუნებრივ ენაზე\n",
    "    - გამომავალი: პროგრამული კოდი\n",
    "    - მაგალითი: \"შექმენი ფუნქცია, რომელიც დაითვლის ფიბონაჩის მიმდევრობას\" → [შესაბამისი Python კოდი]\n",
    "\n",
    "- ტექსტიდან მეტყველების სინთეზი:\n",
    "    - შემავალი მიმდევრობა: წერილობითი ტექსტი\n",
    "    - გამომავალი მიმდევრობა: ფონემების ან აუდიო სიგნალების მიმდევრობა\n",
    "    - მაგალითი: \"გამარჯობა\" → [სიტყვის შესაბამისი გახმოვანება]\n",
    "\n",
    "- ხმის ამოცნობა (ტრანსკრიფცია):\n",
    "    - შემავალი მიმდევრობა: აუდიო სიგნალების მიმდევრობა\n",
    "    - გამომავალი მიმდევრობა: ტრანსკრიპტი ტექსტის სახით\n",
    "    - მაგალითი: [აუდიო ფაილი] → \"გამარჯობა, როგორ ხარ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a33f24de735e6",
   "metadata": {},
   "source": [
    "<video src=\"https://lena-voita.github.io/resources/lectures/seq2seq/general/enc_dec_prob_idea.mp4\" controls autoplay loop style=\"display: block; margin: 0 auto\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed695105",
   "metadata": {},
   "source": [
    "ამგვარი ამოცანების გადაჭრისთვის Encoder-Decoder არქიტექტურა გამოიყენება:\n",
    "\n",
    "- Encoder - კითხულობს მთელს შემავალი მიმდევრობას X = (x₁, x₂, ..., xₙ) და ქმნის მის კარგ რეპრეზენტაციას;\n",
    "- Decoder - იყენებს Encoder-ის რეპრეზენტაციას სამიზნე მიმდევრობის დასაგენერირებლად.\n",
    "\n",
    "როგორც წესი, დეკოდირება ნაბიჯ-ნაბიჯ ხდება. მაგალითად, მანქანური თარგმნის შემთხვევაში, წინადადების თარგმანი სიტყვა-სიტყვა გენერირდება. Decoder თითოეული სიტყვის დაგენერირებამდე გვაძლევს სავარაუდო სიტყვების ალბათურ განაწილებას, საიდანაც შეგვიძლია ამოვირჩიოთ ყველაზე შესაფერისი კანდიდატი.\n",
    "\n",
    "ეს პროცესი შეიძლება აღვწეროთ შემდეგნაირად:\n",
    "\n",
    "1. Encoder ამუშავებს შემავალ მიმდევრობას _X_ და ქმნის კონტექსტუალურ რეპრეზენტაციას _C_.\n",
    "1. Decoder იწყებს გამომავალი მიმდევრობის _Y_ გენერირებას, იყენებს რა _C_-ს და უკვე დაგენერირებულ სიმბოლოებს.\n",
    "1. თითოეული ნაბიჯისთვის _t_, Decoder აგენერირებს ალბათურ განაწილებას _P(yₜ|y₁, ..., yₜ₋₁, C)_ მომდევნო სიმბოლოსთვის.\n",
    "1. ამ განაწილებიდან ირჩევა ყველაზე სავარაუდო სიტყვა (ტოკენი).\n",
    "1. პროცესი გრძელდება, სანამ არ დაგენერირდება სპეციალური დასრულების სიმბოლო ან არ მიიღწევა წინასწარ განსაზღვრული მაქსიმალური სიგრძე."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539b353",
   "metadata": {},
   "source": [
    "# Transformer: Attention is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e361ca",
   "metadata": {},
   "source": [
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/transformer/model-min.png\" width=600 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704d06c8",
   "metadata": {},
   "source": [
    "2017 წელს Google-ის მკვლევარებმა თავიანთ ნაშრომში (Attention is All You Need) გამოაქვეყნეს Transformer არქიტექტურა. როგორც სახელიდან ჩანს ამ არქიტექტურის ფუნდამენტს წარმოადგენს Attention მექანიზმი, რომელიც 2014 წლიდან გამოიყენებოდა seq-to-seq ამოცანების გადაჭრაში. მთავარი უპირატესობები, რაც ამ არქიტექტურამ წინამორბედებთან შედარებით აჩვენა:\n",
    "- შეუძლია შემავალი მიმდევრობის პარალელური დამუშავება GPU-ს გამოყენებით, მაშინ როცა რეკურენტული ნეირონული ქსელები (RNN) შემავალ ინფორმაციას სიტყვა-სიტყვა ამუშავებენ;\n",
    "- შეუძლია გაცილებით გრძელ ტექსტებთან მუშაობა ხარისხის დაკარგვის გარეშე;\n",
    "- პარალელურობის გამო მარტივად შეიძლება ამ არქიტექტურის მასშტაბირება;\n",
    "- გაცილების ჩქარი ტრეინინგი;\n",
    "- მნიშვნელოვნად გაუმჯობესებული შედეგები ენის მოდელირების, თარგმნის, კითხვებზე პასუხის გაცემის და სხვა NLP ამოცანებში."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36740cae",
   "metadata": {},
   "source": [
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/transformer/rnn_vs_transformer_river-min.png\" width=600 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c7e6f",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafbd97e",
   "metadata": {},
   "source": [
    "<img src=\"./images/Encoder.png\" width=200 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b8b3e",
   "metadata": {},
   "source": [
    "მთავარი დიაგრამის მარცხენა ნაწილი - Encoder ამუშავებს შემომავალ მიმდევრობას, შედგება N ცალი მიმდევრობით გადაბმული Encoder ბლოკისაგან (ნაცრისფერი ნაწილი), რომელთაგან თითოეული:\n",
    "\n",
    "1. Self-Attention მექანიზმით:\n",
    "    - თითოეული ტოკენის რეპრეზენტაცია \"ყურადღებას\" აქცევს სხვა ტოკენებს.\n",
    "    - ეს საშუალებას აძლევს მოდელს, გაითვალისწინოს მთელი ტექსტის/მიმდევრობის კონტექსტი.\n",
    "\n",
    "1. Feed-Forward ქსელით:\n",
    "    - ანახლებს/გარდაქმნის კონკრეტული ტოკენის რეპრეზენტაციას.\n",
    "    - ზრდის მოდელის უნარს, დაამუშავოს რთული პატერნები."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c5c86",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c57e1",
   "metadata": {},
   "source": [
    "<img src=\"./images/Decoder.png\" width=200 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79980f278b58fb2",
   "metadata": {},
   "source": [
    "მთავარი დიაგრამის მარჯვენა ნაწილი - Decoder იღებს Encoder-ის საბოლოო layer-ის რეპრეზენტაციებს და აგენერირებს სამიზნე მიმდევრობას. ისიც, Encoder-ის მსგავსად, შედგება N ცალი მიმდევრობით გადაბმული Decoder ბლოკისაგან (ნაცრისფერი ნაწილი), რომელთაგან თითოეული:\n",
    "\n",
    "1. Masked Self-Attention მექანიზმით:\n",
    "    - ამუშავებს უკვე დაგენერირებულ ტოკენებს და \"ყურადღებას\" აქცევს მათ.\n",
    "\n",
    "1. Encoder-Decoder Attention მექანიზმით:\n",
    "    - აკავშირებს Decoder-ის მიმდინარე მდგომარეობას Encoder-ით მიღებულ ტოკენის რეპრეზენტაციებთან.\n",
    "    - საშუალებას აძლევს Decoder-ს, ფოკუსირდეს შემავალი მიმდევრობის რელევანტურ ნაწილებზე.\n",
    "\n",
    "1. Feed-Forward ქსელით:\n",
    "    - ანახლებს/გარდაქმნის თითოეული ტოკენის რეპრეზენტაციას.\n",
    "    - ზრდის მოდელის უნარს, დაამუშაოს რთული პატერნები."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e102c4",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d42c2d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "    <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/eMlx5fFNoYc?si=JxbTq5Izf61d7gWN\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d1877c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V\n",
    "$$\n",
    "\n",
    "სადაც:\n",
    "- _Q_ არის Query მატრიცა\n",
    "- _K_ არის Key მატრიცა\n",
    "- _V_ არის Value მატრიცა\n",
    "- _d_k_ არის Key ვექტორის განზომილება\n",
    "\n",
    "Attention მექანიზმი საშუალებას აძლევს მოდელს ფოკუსირდეს შემავალი მონაცემების სხვადასხვა ნაწილზე, თითოეული ტოკენის დამუშავების დროს. ეს ეხმარება მოდელს უკეთ გაიგოს კონტექსტი და დაიჭიროს რთული ურთიერთკავშირები სიტყვებს შორის. ამ მექანიზმით \"მდიდრდება\" ტრანსფორმერის თითოეულ შრეზე ტოკენების რეპრეზენტაცია.  \n",
    "\n",
    "1) Self-Attention თითოეული ტოკენისათვის იყენებს Query, Key და Value ვექტორებს, რომლებიც მიმდინარე შრის embedding-ის შედარებით პატარა განზომილებიან სივრცეში წრფივი პროექციით მიიღება:\n",
    "    - Query (Q): მიმდინარე ტოკენის რეპრეზენტაცია\n",
    "    - Key (K): სხვა ტოკენების რეპრეზენტაცია, რომლებთანაც შედარდება Q\n",
    "    - Value (V): ინფორმაცია, რომელიც გამოიყენება საბოლოო output-ის შესაქმნელად\n",
    "\n",
    "\n",
    "2) Attention-ის გამოთვლა:\n",
    "    1) Q და K-ს სკალარული ნამრავლის გამოთვლა\n",
    "    2) შედეგის გაყოფა sqrt(d_k)-ზე, სადაც d_k არის Key ვექტორის ზომა\n",
    "    3) Softmax ფუნქციის გამოყენება ნორმალიზებული წონების მისაღებად\n",
    "    4) ამ წონების გამრავლება V ვექტორებზე\n",
    "\n",
    "3) Cross-Attention:\n",
    "    - Decoder-ში ყურადღება ექცევა Encoder-ის მიერ შექმნილ რეპრეზენტაციებს, ამას cross-attention ეწოდება.\n",
    "\n",
    "4) Multi-Head Attention:\n",
    "Transformer იყენებს რამდენიმე Attention \"თავს\" პარალელურად, რაც საშუალებას აძლევს მოდელს ყურადღება მიაქციოს სხვადასხვა ტიპის ურთიერთობებს.\n",
    "\n",
    "5) Attention-ის უპირატესობები:\n",
    "    - შეუძლია დაამუშაოს გრძელი დამოკიდებულებები შემავალ მონაცემებში\n",
    "    - პარალელიზაციის საშუალებას იძლევა, რაც აჩქარებს სწავლებასა და ინფერენსს\n",
    "    - უზრუნველყოფს მოდელის ინტერპრეტირებადობას Attention წონების ვიზუალიზაციით ([მაგალითები და playground](https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ?usp=sharing))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4727c4",
   "metadata": {},
   "source": [
    "### ტექსტის გენერაცია"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b465a1",
   "metadata": {},
   "source": [
    "<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/transformer/transformer_original.gif\" width=600 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a23489",
   "metadata": {},
   "source": [
    "ამ ანიმაციაზე ნაჩვენებია ენკოდირებისა და დეკოდირების დროს რეპრეზენტაციების მიმოცვლა.\n",
    "\n",
    "Encoding:\n",
    "1. ენკოდირება იწყება სიტყვების \"I\" \"arrived\" \"at\" \"the\" საწყისი ემბედინგებით (ცარიელი შავი რგოლები);\n",
    "1. self-attention-ით ხდება ამ ტოკენების რეპრეზენტაციების \"გამდიდრება\" (ერთმანეთზე ყურადღების მიქცევა);\n",
    "1. რგოლის შევსება/გაფერადება ნიშნავს feed-forward layer-ის გავლას;\n",
    "1. self-attention და feed-forward მეორდება 3-ჯერ (ამ ანიმაციაში N=3);\n",
    "\n",
    "Decoding:\n",
    "1. ენკოდირებისგან განსხვავებით დეკოდირება არა პარალელურად, არამედ სიტყვა-სიტყვა მიმდინარეობს;\n",
    "1. აქაც ვიწყებთ საწყისი ემბედინგებით (ცარიელი შავი რგოლები);\n",
    "1. self-attention-ით უკვე დაგენერირებულ ტოკენებს ექცევა ყურადღება;\n",
    "1. cross-attention-ით ყურადღება ექცევა encoder-დან წამოსულ ტოკენებს;\n",
    "1. რგოლის შევსება/გაფერადება ნიშნავს feed-forward layer-ის გავლას;\n",
    "1. self-attention, cross-attention და feed-forward მეორდება 3-ჯერ (ამ ანიმაციაშიც N=3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b83ff1",
   "metadata": {},
   "source": [
    "როგორც ხედავთ, Encoder-ისა და Decoder-ის არქიტექტურა თითქმის იდენტურია, განსხვავება მხოლოდ Decoder-ის cross-attention-ია, როდესაც იგი ყურადღებას აქცევს Encoder-ის მიერ შექმნილ შემავალი მიმდევრობის რეპრეზენტაციებს."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb33db",
   "metadata": {},
   "source": [
    "# ტრანსფორმერების სხვა გამოყენებები"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29499b",
   "metadata": {},
   "source": [
    "<img src=\"https://1.bp.blogspot.com/-_mnVfmzvJWc/X8gMzhZ7SkI/AAAAAAAAG24/8gW2AHEoqUQrBwOqjhYB37A7OOjNyKuNgCLcBGAsYHQ/s1600/image1.gif\" width=600 style=\"display: block; margin: 0 auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedfb80e",
   "metadata": {},
   "source": [
    "Transformer არქიტექტურა თავისი მარტივად მასშტაბირებადობისა და შედეგების გამო აქტიურად გამოიყენება არატექსტურ ამოცანებშიც - მაგალითად, სურათების კლასიფიცირებაში. რადგან ეს დავალება გენერაციას არ მოითხოვს, შეგვიძლია ავიღოთ მხოლოდ Encoder ნაწილი.  [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/pdf/2010.11929) - ამ ნაშრომში ავტორებმა აჩვენეს თუ რამდენად კარგად შეუძლიათ ტრანსფორმერებს ალტერნატიული არქიტექტურების (CNN, ResNet) ჩანაცვლება სურათების კლასიფიკაციის ამოცანაში.\n",
    "\n",
    "ერთადერთი მოდიფიკაცია, რაც სხვადასხვა კატეგორიის input-ზე მოსარგებადაა საჭირო, არის Embedding layer-ის მოდიფიცირება. სურათების შემთხვევაში, როგორც წესი, ფოტო \"იჭრება\" პატარ პატარა ფრაგმენტებად (მაგ. 16x16 პიქსელი). სწორედ ეს ფრაგმენტები არის ტექსტური ტოკენების ანალოგი ამ შემთხვევაში."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daa5da0",
   "metadata": {},
   "source": [
    "# იმპლემენტაცია\n",
    "\n",
    "Transformer არქიტექტურის თითოეული კომპონენტის საგანმანათლებლო იმპლემენტაცია შეგიძლიათ იხილოთ [Annotated Transformer | MIT](https://nlp.seas.harvard.edu/annotated-transformer/) ბლოგში.\n",
    "რა თქმა უნდა ML ბიბლიოთეკები, როგორიცაა PyTorch და TensorFlow გვაძლევს უკვე გამზადებულ კომპონენტებს, რომლებიც შეგიძლიათ გამოიყენოთ თქვენს პროექტებში."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "ncVKzdbH9WNH",
        "outputId": "e66a4f72-5d4f-43c2-803d-b7bd7d4ada4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<div style=\"text-align: center;\">\n",
              "    <div style=\"font-size: 34px; margin-bottom: 20px; color: #8ab4f7;\"></div>\n",
              "    <iframe src=\"https://giphy.com/embed/YOjP742CyBbg0zKCbl\" width=\"800\" height=\"392\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n",
              "</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "centered_html_with_title = lambda source, title: f\"\"\"\n",
        "<div style=\"text-align: center;\">\n",
        "    <div style=\"font-size: 34px; margin-bottom: 20px; color: #8ab4f7;\">{title}</div>\n",
        "    <iframe src=\"{source}\" width=\"800\" height=\"392\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n",
        "</div>\n",
        "\"\"\"\n",
        "display(HTML(centered_html_with_title(\"https://giphy.com/embed/YOjP742CyBbg0zKCbl\", \"\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9LN983Ce9ZIp"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from IPython.display import HTML, display, Image, YouTubeVideo\n",
        "from IPython.core.magic import register_line_magic\n",
        "# just for styling pprint function. nothing special\n",
        "\n",
        "def print_html(line, background_color):\n",
        "  display(HTML(f\"\"\"\n",
        "  <div style=\"display: inline-block; font-size:120%; border:1px solid black; padding: 15px; background-color: {background_color}; color: black; margin-bottom: 10px; border-radius:10px; border-width: 1px; border-style: solid; border-color: white; box-sizing: border-box;\">\n",
        "      {line}\n",
        "  </div>\n",
        "  \"\"\"))\n",
        "\n",
        "\n",
        "@register_line_magic\n",
        "def note(line):\n",
        "  print_html(line, \"#94d4f5\")\n",
        "\n",
        "\n",
        "@register_line_magic\n",
        "def warning(line):\n",
        "  print_html(line, \"#f59494\")\n",
        "\n",
        "\n",
        "\n",
        "styled_text_html = lambda x: f\"\"\"\n",
        "<div style=\"padding:20px; color:#150d0a; margin:10px; font-size:220%; text-align:center; display:block; border-radius:20px; border-width: 1px; border-style: solid; border-color: white; background-color: #94d4f5; overflow:hidden;font-weight:500\">\n",
        "{x}</div>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F7_zL0Z98fV"
      },
      "source": [
        "# 📍 ლექციის გეგმა"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "t4gsPNoC92VY",
        "outputId": "9c3e7fb4-adbd-4d11-a61e-3f4fcb2d1131"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<div style=\"padding:20px; color:#150d0a; margin:10px; font-size:220%; text-align:center; display:block; border-radius:20px; border-width: 1px; border-style: solid; border-color: white; background-color: #94d4f5; overflow:hidden;font-weight:500\">\n",
              "📍 ლექციის გეგმა</div>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "display(HTML(styled_text_html(\"📍 ლექციის გეგმა\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHXiztV4BkjL"
      },
      "source": [
        "# ძირითადი პრინციპები \"წინასწარი დასწავლის\" (Pretraining) - ის დროს\n",
        "\n",
        "- დარწმუნდით რომ თქვენს მოდელს შეუძლია დაამუშაობს დიდი რაოდენობის განსხვავებული ტექსტები\n",
        "- არ გამოიყენოთ მარკირებული მონაცემები (წინააღმდეგ შემთხვევაში დიდ მაშტაბზე ვერ გახვალთ!)\n",
        "- დარწმუნდით რომ გაქვთ მაშტაბირებადი კომპიუტერული რესურსი"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "XU_1XiPhDC0B",
        "outputId": "55a49741-a485-45cf-a921-87f49aea92a4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/g0rpYwqJ/0-c-ZXn-AEouh74p-Cb-Xf.webp\" width=1000 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/g0rpYwqJ/0-c-ZXn-AEouh74p-Cb-Xf.webp\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=1000 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elwXwW5VBp1I"
      },
      "source": [
        "# მოდელების წინასწარი დასწავლა სიტყვების ვექტორებიდან"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BpSObxilp9P"
      },
      "source": [
        "> “You shall know a word by the company it keeps” (J. R. Firth 1957: 11)\n",
        "\n",
        "\n",
        "\n",
        "*Consider I **record** the **record**: the two instances of record mean different things.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "0zZ8i37Rre46",
        "outputId": "2dba1691-d537-40d8-8697-0c448c058f42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/LXG8BpKr/Screenshot-2024-06-25-at-22-22-09.png\" width=600 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title **როგორ ვაკეთებდით ადრე?**: დავატრენინგოთ სიტყვების ვექტორები (word embeddings)\n",
        "url = \"https://i.postimg.cc/LXG8BpKr/Screenshot-2024-06-25-at-22-22-09.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=600 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BN5x3kPrfqQ"
      },
      "source": [
        "- დაატრენინგეთ სიტყვების ვექტორები (კონტექსტის გარეშე!)\n",
        "- კონტექსტის შემოტანა LSTM-ში ან Transformer-ში"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "X1WttQgorfFb",
        "outputId": "327e3d4a-b53c-4b0c-a689-3b8425d429aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/wTXjJZWG/Screenshot-2024-06-25-at-22-37-26.png\" width=600 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title **როგორ ვაკეთებთ ახლა?**: დავატრენინგოთ მთლიანი მოდელი\n",
        "url = \"https://i.postimg.cc/wTXjJZWG/Screenshot-2024-06-25-at-22-37-26.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=600 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdqEKvaws2Od"
      },
      "source": [
        "- თანამედროვე NLP-ში პარამეტრი მოდელში ინიციალიზდება წინასწარი ტრენირების გზით.\n",
        "- წინასწარი ტრენირების მეთოდები მალავენ შემავალი მონაცემების ნაწილებს მოდელისგან და ავარჯიშებენ მოდელს ამ ნაწილების აღდგენაზე"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cszoJTb1tMJP"
      },
      "source": [
        "## რა შეუძია მოდელს ისწავლოს დამალული სიტყვების აღდგენისგან?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbAhnNaLtOzj"
      },
      "source": [
        "- თბილისი არის ___ დედაქალაქი\n",
        "- მე ვიყავი ზღვაზე და ვნახე თევზები, კუები და ___\n",
        "- საერთო ჯამში, ამ ორი საათის ფილმის ყურებიდან მიღებული ღირებულება იყო მხოლოდ პოპკორნისა და ___ დალევა\n",
        "- სკოლაში ვისწავლე რიცვხბის მიმდევრობა 1, 1, 2, 3, 5, 8, 13, 21 ___\n",
        "- ქალი გზაზე გადასასვლელთან გაჩერდა და ახედა ___\n",
        "- მე დავდე ___ ჩანგალი მაგიდაზე.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "vjGVeL-5y-3h",
        "outputId": "ece12ed4-27a2-4a5a-a0b8-faf0211bc0dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/9M7j7vkH/Screenshot-2024-06-10-at-02-10-41.png\" width=1000 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/9M7j7vkH/Screenshot-2024-06-10-at-02-10-41.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=1000 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rd67NljEd9A"
      },
      "source": [
        "# Pretraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur7A8plZvkE0"
      },
      "source": [
        "language modeling task:\n",
        "- დავთვალოთ $p_\\theta(w_t|w_{1:t-1})$, ალბათონის განაწილება სიტყვებზე წინა კონტექსტზე დაყრდნობით\n",
        "- ამისთვის ბევრი ტექსტი არსებობს (ინგლისურად!) დავატრენინგოთ ენობრივი მოდელირების მეშვეობით\n",
        "- გავწვრთნათ ნეირონული ქსელი ენის მოდელირების შესასრულებლად დიდი რაოდენობის ტექსტზე.\n",
        "- შეინახეთ ქსელის პარამეტრები ფაილში"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOBQthj8yfDs"
      },
      "source": [
        "საიდან გვაქვს დიდი მონაცემები?\n",
        "\n",
        "- The Pile\n",
        "- RedPajama\n",
        "- RefinedWeb\n",
        "- FineWeb\n",
        "- DataComp-LM [**240 Trillion token**] 🤯\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt_ejBhZzMax"
      },
      "source": [
        "# მოდელის დატრენინგების 3 გზა"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-9dxq_UzQ-O"
      },
      "source": [
        "1. ენკოდერი\n",
        "2. ენკოდერ - დეკოდერი\n",
        "3. დეკოდერი"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGL_izQuzSVR"
      },
      "source": [
        "## 1. ენკოდერი"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "t9cFDMYTztAf",
        "outputId": "a83f4aa0-529a-4ac2-8887-81de6c6a30c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/nh5VtxMM/Screenshot-2024-06-25-at-23-09-57.png\" width=500 height=200></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/nh5VtxMM/Screenshot-2024-06-25-at-23-09-57.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=500 height=200></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "lp7s1HbR3g-E",
        "outputId": "03c5a7c9-131b-4713-a24d-722980d9117d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/0N8nxT3R/Screenshot-2024-06-25-at-23-25-08.png\" width=600 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/0N8nxT3R/Screenshot-2024-06-25-at-23-25-08.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=600 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLhQYmtN3PNQ"
      },
      "source": [
        "- აქამდე ჩვენ ვნახეთ მოდელების წინასწარი სწავლება (pretraining) მაგრამ ენკოდერს აქვს ორმხრივი კავშირი. ორივე მხარეს იყურება შესაბაბისად აქ მსგავს ტრენირებას ვერ გავაკეთებთ\n",
        "- იდეა: სიტყვების რაღაც რაოდენობა ჩავანაცვლოთ ტოკენით [MASK] და გამოვაცნობინოთ ეს სიტყვები\n",
        "\n",
        "h₁, ... , h_T = Encoder(w₁, ... , w_T)\n",
        "y_i ~ Ah_i + b\n",
        "\n",
        "ლოსი მხოლოდ ამ სიტყვებზე დავთვალოთ რომელიც დამასკული იყო თუ x̃ არის x -ის დამასკული ტოკენი, მოდელი სწავლობს p_θ(x|x̃)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrP5ST-W3xhT"
      },
      "source": [
        "**BERT: Bidirectional Encoder Representations from Transformers**\n",
        "\n",
        "Devlin et al., 2018 proposed the “Masked LM” objective and released the weights of a pretrained Transformer, a model they labeled BERT.\n",
        "\n",
        "რამდენიმე დეტალი ბერტის ფეიფერიდან\n",
        "- Predict a random 15% of (sub)word tokens.\n",
        "- Replace input word with [MASK] 80% of the time\n",
        "- Replace input word with a random token 10% of the time\n",
        "- Leave input word unchanged 10% of the time (but still predict it!)\n",
        "- Why? Doesn’t let the model get complacent and not\n",
        "build strong representations of non-masked words.\n",
        "(No masks are seen at fine-tuning time!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "2BQILtBN4F5b",
        "outputId": "d6331742-e020-49a7-bf92-2491109359a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/9fFk1wc7/Screenshot-2024-06-25-at-23-29-40.png\" width=700 height=600></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/9fFk1wc7/Screenshot-2024-06-25-at-23-29-40.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=700 height=600></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDMgkNpW4Evd"
      },
      "source": [
        "დეტალები BERT-ის შესახებ\n",
        "\n",
        "2 მოდელი გამოუშვეს\n",
        "- BERT-base: 12 layers, 768-dim hidden states, 12 attention heads, 110 million params.\n",
        "- BERT-large: 24 layers, 1024-dim hidden states, 16 attention heads, 340 million params.\n",
        "\n",
        "დაატრენინგეს\n",
        "- BooksCorpus (800 მილიონი სიტყვა)\n",
        "- English Wikipedia (2,500 მილიონი სიტყვა)\n",
        "\n",
        "ტრენირება არის ძვირი და არაპრაქტიკული 1 GPU-ზე.\n",
        "- ბერტს ატრენინგებდნენ 64 TPU-ზე 4 დღის განმავლობაში (TPUs სპეციალურად ოპტიმიზებული ტენზორების ოპერაციებზე)\n",
        "\n",
        "ფაინტუნინგი შეიძლება 1 GPU ზე\n",
        "- “დაატრენინგეთ ერთხელ დააფაინტუნეთ ბევრჯერ”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIYsaLpg41Rt"
      },
      "source": [
        "**ენკოდერის შეზღუდვები**\n",
        "\n",
        "შედეგები ძალიან კარგი აქვს და რატომ არ შეიძლება ენკოდერი გამოვიყენოთ ყოველთვის?\n",
        "\n",
        "თუ თქვენი ამოცანა მოიცავს სიტყვების თანმიმდევრულ გენერირებას, მაშინ საჭიროა წინასწარ გაწვრთნილი დეკოდერის გამოყენება; BERT და სხვა წინასწარ გაწვრთნილი ენკოდერები ბუნებრივად არ მუშაობს ავტორეგრესიულ (თითო სიტყვა ყოველ ჯერზე) მეთოდებზე"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "Uvf4yx2V4Dl1",
        "outputId": "62e94ac9-6363-4169-d9ad-f08c62d1f104"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/zvcDXYpd/Screenshot-2024-06-25-at-23-33-41.png\" width=1400 height=400></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/zvcDXYpd/Screenshot-2024-06-25-at-23-33-41.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=1400 height=400></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThYsDPuN4-tq"
      },
      "source": [
        "**ბერტის განახლებული ვარიანტი**\n",
        "\n",
        "ამის შემდეგ იყო ბერტის ბევრი ვარიაცია როგორიცაა RoBERTa, SpanBERT, +++\n",
        "\n",
        "BERT-ის რამდენიმე ცნობილი გაუმჯობესება:\n",
        "\n",
        "- RoBERTa: უფრო დიდი ხნით დატრენინგება, მოაშორეთ შემდეგი წინადადების გამოცნობა\n",
        "- SpanBERT: სიტყვების დამასკვა მიყოლებით უფრო ართულებს ამოცანას და უფრო კარგად მუშაობს"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "N_SxJjW96umn",
        "outputId": "5f67f53d-1030-4d68-e21c-26e8885317b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/7hFvWHKy/Screenshot-2024-06-25-at-23-40-15.png\" width=1000 height=400></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/7hFvWHKy/Screenshot-2024-06-25-at-23-40-15.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=1000 height=400></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqQci89c6SgC"
      },
      "source": [
        "დასვკნა RoBERTa-ს ფეიფერიდან:\n",
        "- მეტი გამოთვლითი რესურსი\n",
        "- მეტი მონაცემს შეუძლია გააუმჯობესოს შედეგი ისე რომ სხვა არაფერი შევცვალოთ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "zZ1z0CzTzzJO",
        "outputId": "4c2363fb-5799-4805-e6ea-b4ed6467d36a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/B6fqXCT0/Screenshot-2024-06-25-at-23-10-00.png\" width=500 height=300></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title ენკოდერ - დეკოდერი\n",
        "url = \"https://i.postimg.cc/B6fqXCT0/Screenshot-2024-06-25-at-23-10-00.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=500 height=300></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Fue49Y69Qf"
      },
      "source": [
        "ენკოდერ - დეკოდერის შემთხვევაში, ჩვენ შეგვიძლია გავაკეთოთ შემდეგი სიტყვის გამოცნობა. ამ შემთხვევაში ენკოდერი იღებს წინადადებას მაგრამ არ აკეთებს გამოცნობას\n",
        "\n",
        "ენკოდერი ხედავს მთლიანად წინადადებას, დეკოდერი გამოიყენება გენერაციისთვის აუტორეგრეისულად"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "TL6PjXpj7JcE",
        "outputId": "9e33c4cc-dec7-49c6-98e8-656cf809cdc0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/BQFf1FvZ/Screenshot-2024-06-25-at-23-42-52.png\" width=600 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/BQFf1FvZ/Screenshot-2024-06-25-at-23-42-52.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=600 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Do0h9AWozz1j",
        "outputId": "077c5de1-9f98-4224-c62d-15d219e8d7cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/pVZ2Lzyw/Screenshot-2024-06-25-at-23-10-03.png\" width=500 height=200></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title დეკოდერი\n",
        "url = \"https://i.postimg.cc/pVZ2Lzyw/Screenshot-2024-06-25-at-23-10-03.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=500 height=200></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drvDzMiL9Sa4"
      },
      "source": [
        "ამ შემთხვევაში ბუნებრივად შეიძლება აუტორეგრესიულად მოდელის გაწვრთნა და სიტყვების გენერირება წინა კონტექსტის საფუძველზე\n",
        "\n",
        "- დიალოგი (კონტექსტი=დიალოგის ისტორია)\n",
        "- ტექსტის შემოკლება (კონტექსტი=ტექსტი)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc3OFlvf9aZ6"
      },
      "source": [
        "# GPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZpQjwG_9aSX"
      },
      "source": [
        "2018 წელს გამოვიდა GPT რაც იყო დიდი მიღწევა აუტორეგრესიულ მოდელებში\n",
        "\n",
        "- დეკოდერი 12 ლეიერით, 117M პარამეტრით.\n",
        "- 768-განზომილებიანი hidden states, 3072-განზომილებიანი feed-forward hidden layers.\n",
        "- Byte-pair encoding 40,000 შეერთებით\n",
        "- დააატრენინგეს BooksCorpus-ზე რაც იყო 7000 უნიკალურ წიგნზე მეტი\n",
        "- შეიცავა დიდ ტექსტებს რათა მოდელს ესწავლა გრძელ ტექსტებზე დამოკიდებულება\n",
        "- აკრონიმი “GPT” არ უხსენებიათ ფეიფერში მაგრამ როგორც ვიცით ის იშიფრება როგორც:“Generative PreTraining” ან “Generative Pretrained Transformer”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyc8zRg69qVc"
      },
      "source": [
        "# GPT 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzvxspk29sJi"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvIg5-dZ9srl"
      },
      "source": [
        "# GPT 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzy5bt1x9sFP"
      },
      "source": [
        "აქამდე, ჩვენ განვიხილეთ 2 ვარიანტი:\n",
        "\n",
        "- ვიღებთ მაგალითს (prompt) გაანწილებიდან და ვაწვდით მოდელს\n",
        "- ვაკეთებთ მოდელის ფაინტუნინგს და ვიღებთ უკეთეს პასუხებს სპეციფიკური ამოცანებისთვის\n",
        "\n",
        "ძალიან დიდი ენობრივი მოდელები, როგორც ჩანს, ახორციელებენ გარკვეული სახის სწავლას გრადიენტის გარეშე, უბრალოდ მათ კონტექსტში მოწოდებული მაგალითებიდან.\n",
        "\n",
        "GPT-3 არის ამის მაგალითი. ყველაზე დიდ T5 მოდელს ჰქონდა 11 მილიარდი პარამეტრი.\n",
        "GPT-3-ს აქვს 175 მილიარდი პარამეტრი."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CweAgYO-HDk"
      },
      "source": [
        "# მასშტაბირების ეფექტურობა"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzfho5et-Idf"
      },
      "source": [
        "GPT-3 იყო 175B პარამეტრიანი მოდელი რომელიც დაატრენინგეს 300B ტოკენზე\n",
        "\n",
        "უხეშად დანახარჯი დატრენინგებისას არის პარამეტრების რაოდენობა * სატრენინგო მონაცემების რაოდენობაზე\n",
        "\n",
        "OpenAI-მ სწორი პარამეტრ - ტოკენის ფარდობა აირჩია საუკეთესო მოდელის მისაღებად? არა."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "noA-cjy--oey",
        "outputId": "502e3b2b-c78d-4075-ce64-7e20981df2f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/3RWxMwFy/Screenshot-2024-06-25-at-23-58-23.png\" width=900 height=300></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/3RWxMwFy/Screenshot-2024-06-25-at-23-58-23.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=900 height=300></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "XPpiBVM8D2eU",
        "outputId": "03b19180-f376-4dc5-d145-4bea1b65d055"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/d3jtJhDw/Screenshot-2024-06-26-at-00-18-57.png\" width=1000 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/d3jtJhDw/Screenshot-2024-06-26-at-00-18-57.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=1000 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "Sm6cZzeJD-xS",
        "outputId": "212b4e7b-1e42-43ff-ade2-9f02f368e8db"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/L6m8N30X/Screenshot-2024-06-26-at-00-18-45.png\" width=1200 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/L6m8N30X/Screenshot-2024-06-26-at-00-18-45.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=1200 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "jvK-kDqhG9Hm",
        "outputId": "062e98eb-99fe-4da2-8438-f14fe47399da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/LXfrXjqH/Screenshot-2024-06-10-at-02-13-41.png\" width=1000 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/LXfrXjqH/Screenshot-2024-06-10-at-02-13-41.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=1000 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "jTkHvNd4G_N-",
        "outputId": "cb3f4a3a-d845-41c8-bbbd-21c0ece9307b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><img src=\"https://i.postimg.cc/2jQsNFRG/Screenshot-2024-06-10-at-02-15-32.png\" width=1000 height=500></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "url = \"https://i.postimg.cc/2jQsNFRG/Screenshot-2024-06-10-at-02-15-32.png\"\n",
        "centered_image = HTML(f'<div style=\"text-align:center;\"><img src=\"{url}\" width=1000 height=500></div>')\n",
        "display(centered_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "fH8iFGdnHCGX",
        "outputId": "688fc801-0af3-4afb-d730-5c24d104bfe9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"text-align:center;\"><iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/zjkBMFhNj_g\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "video_id = \"zjkBMFhNj_g\"  # Replace with the actual YouTube video ID\n",
        "\n",
        "embed_code = f'<iframe width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/{video_id}\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'\n",
        "\n",
        "centered_video = HTML(f'<div style=\"text-align:center;\">{embed_code}</div>')\n",
        "display(centered_video)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2kDbV6aj3Lk"
      },
      "source": [
        "# asd\n",
        "\n",
        "- modern llm pretraining\n",
        "- in context learning / chain of thought\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HouE21lbz5O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49d8e88e-29c8-446c-b82f-3718218fd3f2",
   "metadata": {},
   "source": [
    "## ლექცია 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d9318-d993-4e9d-99c2-314bf6502faf",
   "metadata": {},
   "source": [
    "### მონაცემთა აუგმენტაცია\n",
    "\n",
    "მონაცემთა აუგმენტაცია არის ტექნიკა, რომელიც გამოიყენება გასაწვრთნელი მონაცემების ვარიაციის გასაზრდელად/მოსაგროვებლად ახალი მონაცემების შეგროვების გარეშე. ეს მეთოდი განსაკუთრებით სასარგებლოა ბუნებრივი ენის დამუშავების (NLP) მიმართულებით, მაგრამ ასევე ფართოდ გამოიყენება კომპიუტერული ხედვისა და სხვა მანქანური სწავლების სფეროებში.\n",
    "\n",
    "მონაცემთა აუგმენტაციის მთავარი მიზნებია:\n",
    "\n",
    "1. მოდელის გენერალიზაციის უნარის გაუმჯობესება\n",
    "2. გადასწავლის შემცირება\n",
    "3. მცირე ზომის მონაცემთა ნაკრებების გაფართოება\n",
    "4. მოდელის მდგრადობის გაზრდა სხვადასხვა ტიპის შემავალი მონაცემების მიმართ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14806655-60f4-4279-9537-d783a82c37ba",
   "metadata": {},
   "source": [
    "### კლასიკური მონაცემთა აუგმენტაციის მეთოდები"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1db435-f504-405d-829d-f4ed470de748",
   "metadata": {},
   "source": [
    "![Alt text](imgs/classical_data_augmentation_methods.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38a741a-101b-44f5-9569-c89bde97f734",
   "metadata": {},
   "source": [
    "### ხელოვნურ ინტელექტზე დაფუძნებული მონაცემთა აუგმენტაციის მეთოდები (დიდი ენობრივი მოდელების გამოყენებით)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9aece8",
   "metadata": {},
   "source": [
    "დიდი ენობრივი მოდელები (LLMs), როგორიცაა OpenAI-ს GPT, Google-ის Gemini ან Meta-ს LLaMa, წარმოადგენს მძლავრ ინსტრუმენტებს მონაცემთა აუგმენტაციისთვის. ეს მოდელები შეიძლება გამოვიყენოთ სხვადასხვა ტიპის მონაცემების გენერირებისთვის, მათ შორის ტექსტის, სურათების აღწერილობების და სხვა სტრუქტურირებული ინფორმაციის შესაქმნელად."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e9e83",
   "metadata": {},
   "source": [
    "#### უპირატესობები:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45faea3d",
   "metadata": {},
   "source": [
    "1. **მრავალფეროვანი და მასშტაბური მონაცემების გენერაცია:** LLM-ებს შეუძლიათ შექმნან დიდი რაოდენობით მრავალფეროვანი მონაცემები სწრაფად და ეფექტურად. ეს განსაკუთრებით სასარგებლოა იმ შემთხვევებში, როდესაც რეალური მონაცემების შეგროვება რთული ან ძვირია.\n",
    "\n",
    "2. **კონფიდენციალურობის დაცვა:** LLM-ების გამოყენებით შესაძლებელია \"ხელოვნური\" მონაცემების შექმნა, რომლებიც სტატისტიკურად მსგავსია რეალური მონაცემებისა, მაგრამ არ შეიცავს პერსონალურ ინფორმაციას. ეს ხელს უწყობს კონფიდენციალურობის დაცვას მგრძნობიარე მონაცემებთან მუშაობისას.\n",
    "\n",
    "3. **ეფექტურობა:** LLM-ები შეიძლება გამოყენებულ იქნას მონაცემთა აუგმენტაციის ავტომატიზებისთვის, რაც ამცირებს ხელით შრომის საჭიროებას და ზრდის პროცესის ეფექტურობას.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772b8dd0",
   "metadata": {},
   "source": [
    "##### გამოწვევები"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3923d59",
   "metadata": {},
   "source": [
    "1. **AI მოდელების სწავლება:** გენერირებული მონაცემები შეიძლება გამოვიყენოთ სხვადასხვა AI მოდელების, მათ შორის კლასიფიკატორების, ენის მოდელების და კომპიუტერული ხედვის სისტემების სწავლებისთვის და გაუმჯობესებისთვის.\n",
    "\n",
    "2. **კვლევები და განვითარება:** ხელოვნური მონაცემები სასარგებლოა ახალი ალგორითმების ტესტირებისთვის და AI სისტემების შემუშავებისთვის, განსაკუთრებით იმ სფეროებში, სადაც რეალური მონაცემები შეზღუდულია (მაგალითად, მედიცინა)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75110ac2",
   "metadata": {},
   "source": [
    "##### გამოწვევები და პრობლემები:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca336a",
   "metadata": {},
   "source": [
    "1. **მონაცემების ხარისხის უზრუნველყოფა:** LLM-ების მიერ გენერირებული მონაცემები ყოველთვის არ არის იდეალური ხარისხის. ზოგჯერ შეიძლება წარმოიქმნას უზუსტობები, შეუსაბამობები ან არარელევანტური ინფორმაცია. ამის გამო, აუცილებელია გენერირებული მონაცემების გულდასმით შემოწმება და ფილტრაცია.\n",
    "\n",
    "2. **მიკერძოების თავიდან აცილება:** LLM-ები შეიძლება ასახავდნენ და აძლიერებდნენ მიკერძოებებს, რომლებიც არსებობს მათ სასწავლო მონაცემებში. ეს შეიძლება გამოიწვიოს არასასურველი ტენდენციები გენერირებულ მონაცემებში, რაც საბოლოოდ გავლენას მოახდენს ამ მონაცემებზე გაწვრთნილ მოდელებზე.\n",
    "\n",
    "3. **რეალისტურობის ნაკლებობა:** მიუხედავად იმისა, რომ LLM-ებს შეუძლიათ დამაჯერებელი ტექსტის გენერირება, ზოგჯერ მათ მიერ შექმნილ მონაცემებს აკლია რეალური სამყაროს ნიუანსები და კომპლექსურობა. ეს შეიძლება პრობლემატური იყოს გარკვეული აპლიკაციებისთვის, რომლებიც მოითხოვენ ძალიან ზუსტ და კონტექსტუალურ ინფორმაციას.\n",
    "\n",
    "4. **ეთიკური საკითხები:** LLM-ების გამოყენება მონაცემთა აუგმენტაციისთვის წამოჭრის ეთიკურ კითხვებს, განსაკუთრებით მაშინ, როდესაც გენერირებული მონაცემები გამოიყენება გადაწყვეტილების მიღების პროცესებში ან მგრძნობიარე აპლიკაციებში.\n",
    "\n",
    "5. **კონტროლის სირთულე:** LLM-ების მიერ გენერირებული შედეგების სრული კონტროლი რთულია. შეიძლება წარმოიქმნას მოულოდნელი ან არასასურველი შედეგები, რაც მოითხოვს დამატებით ძალისხმევას მათ გასაფილტრად ან გასასწორებლად.\n",
    "\n",
    "6. **რესურსების ინტენსიური მოხმარება:** დიდი ენობრივი მოდელების გამოყენება მოითხოვს მნიშვნელოვან გამოთვლით რესურსებს, რაც შეიძლება ძვირი იყოს, განსაკუთრებით მცირე ორგანიზაციებისთვის ან მკვლევარებისთვის."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86044ba",
   "metadata": {},
   "source": [
    "მიუხედავად ამ გამოწვევებისა, LLM-ებზე დაფუძნებული მონაცემთა აუგმენტაცია რჩება მძლავრ ინსტრუმენტად AI-ის განვითარებაში. მნიშვნელოვანია ამ მეთოდების გონივრულად და პასუხისმგებლობით გამოყენება, გამოწვევების გათვალისწინებით და შესაბამისი სტრატეგიების შემუშავებით მათ დასაძლევად."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be839e-cc3a-4d93-8170-1ef1abc12977",
   "metadata": {},
   "source": [
    "![Alt text](imgs/LLM_Pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226a9c5-be33-4dad-8151-89f802a53019",
   "metadata": {},
   "source": [
    "### აუგმენტაციის ტექნიკების პროექტში გამოყენება\n",
    "\n",
    "ენობრივი მოდელების გამოყენებით აუგმენტაცია შეგვიძლია ვიკიპედიისთვისაც გამოვიყენოთ. მაგალითისთვის, შეგვიძლია გამოვიყენოთ შემდეგნაირად:\n",
    "- განვავრცოთ ქართულ ვიკიპედიაში არსებული სტატიები\n",
    "- შევასწოროთ ფორმატი სტაიტებში (საჭიროების შემთხვევაში)\n",
    "- გავაკეთოთ სტატიების პერიფრაზირება\n",
    "- დავამატოთ სრულიად ახალი სტატიები ქართულ ვიკიპედიაში\n",
    "\n",
    "კონკრეტულად ამ შემთხვევაში, შეგვიძლია Anthropic-ის ერთ-ერთი მრავალენოვანი მოდელი - haiku - როგორც დიდი ენობრივი მოდელი. მაგრამ ამისთვის შესაბამისი ინსტრუქცია (მითითება) დაგვჭირდება."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a6b0a",
   "metadata": {},
   "source": [
    "##### მითითება/ინსტრუქცია (prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cdf2af",
   "metadata": {},
   "source": [
    "დიდი ენობრივი მოდელების გამოყენებისას (როგორიცაა, მაგალითად, haiku) მონაცემთა აუგმენტაციისთვის, განსაკუთრებით მნიშვნელოვანია პრომპტების (მითითებების) როლი. პრომპტი არის ტექსტური ინსტრუქცია, რომელიც მოდელს აძლევს მიმართულებას, თუ რა სახის ინფორმაცია უნდა დააგენერიროს. კარგად შედგენილი პრომპტი არის ხელოვნური მონაცემების წარმატებული გენერაციის საწინდარი."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb9b0e",
   "metadata": {},
   "source": [
    "##### მითითების მნიშვნელობა სინთეზური მონაცემების გენერაციაში:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c082f04",
   "metadata": {},
   "source": [
    "1. **განსაზღვრავს გენერირებული მონაცემების ხარისხს და რელევანტურობას**: კარგად ფორმულირებული პრომპტი უზრუნველყოფს, რომ მოდელმა შექმნას ზუსტად ის ტიპის მონაცემები, რაც გვჭირდება.\n",
    "\n",
    "2. **უზრუნველყოფს მონაცემთა მრავალფეროვნებას**: სხვადასხვა პრომპტების გამოყენებით შესაძლებელია მრავალფეროვანი მონაცემების გენერირება, რაც ხელს უწყობს მოდელის უკეთ სწავლებას.\n",
    "\n",
    "3. **აკონტროლებს მონაცემთა სტრუქტურას**: პრომპტის საშუალებით შესაძლებელია მონაცემების კონკრეტული ფორმატით ან სტრუქტურით გენერირება.\n",
    "\n",
    "4. **ეხმარება მიკერძოების თავიდან აცილებას**: კარგად შედგენილი პრომპტები შეიძლება გამოყენებულ იქნას მონაცემთა ნაკრებში არსებული მიკერძოების გამოსასწორებლად.\n",
    "\n",
    "5. **ზრდის ეფექტურობას**: ოპტიმიზირებული პრომპტები საშუალებას გვაძლევს სწრაფად და ეფექტურად მივიღოთ სასურველი შედეგები, რაც ამცირებს რესურსების ხარჯვას."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf38c87",
   "metadata": {},
   "source": [
    "ეფექტური პრომპტინგი მოითხოვს პრაქტიკას და ექსპერიმენტირებას, რათა მივაღწიოთ ოპტიმალურ შედეგებს სინთეზური მონაცემების გენერაციისას. ახლა კი დავუბრუნდეთ პრაქტიკულ მაგალითს:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491018f7-3887-4e11-9334-94a3bae3f6ac",
   "metadata": {},
   "source": [
    "#### გავამზადოთ Antropic API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c6a93b9-a3a9-47b7-b72f-77c6853e031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import anthropic\n",
    "\n",
    "def initialize_anthropic_client():\n",
    "    \"\"\"\n",
    "    ინიციალიზაციას გაუკეთებს Antropic-ის API-ს კლიენტს.\n",
    "    \n",
    "    ფუნქცია იღებს API_KEY-ს გარემოს ცვლადიდან და აბრუნებს \n",
    "    ინიციალიზირებულ Antropic-ის კლიენტს.\n",
    "    \n",
    "    Returns:\n",
    "        anthropic.Anthropic: ინიციალიზებული Antropic-ის კლიენტი.\n",
    "    \"\"\"\n",
    "    # API KEY-ს მიღება გარემოს ცვლადიდან\n",
    "    my_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    \n",
    "    # Antropic-ის API-ს ინიციალიზაცია\n",
    "    client = anthropic.Anthropic(\n",
    "        api_key=my_api_key,\n",
    "    )\n",
    "    \n",
    "    return client\n",
    "\n",
    "client = initialize_anthropic_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9895442-c166-490f-a4bd-f16aa9d93cf2",
   "metadata": {},
   "source": [
    "#### გავამზადოთ Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91da7ecd-7bc4-47f2-a4de-fde7da81916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# განსვსაზღვროთ ფუნქცია, რომელიც მიიღებს სტატიის სახელს და დააგენერირებს შესაბამისს სტატიას\n",
    "# მონაცემთა გენერაციისთის prompt-ს აქვს ძალიან დიდი მნიშვნელობა - ის ეუბნება მოდელს დააგენერიროს ჩვენთვის საჭირო სტატიები\n",
    "def get_user_prompt(article_name):\n",
    "    \"\"\"\n",
    "    აგენერირებს prompt-ს ვიკიპედიის სტილის სტატიის შესაქმნელად ქართულ ენაზე.\n",
    "\n",
    "    არგუმენტები:\n",
    "        article_name (str): სტატიის თემის სახელი.\n",
    "\n",
    "    აბრუნებს:\n",
    "        str: დაფორმატებული prompt, რომელიც მიუთითებს მოდელს დაწეროს მოკლე, \n",
    "             ინფორმაციული ვიკიპედიის სტილის სტატია ქართულ ენაზე, რომელიც შესაფერისი იქნება \n",
    "             ქართულ ვიკიპედიაში დასამატებლად. სტატია უნდა იყოს დაახლოებით 200-500 სიტყვა.\n",
    "             სტატია უნდა იყოს ობიექტური: პირადი მოსაზრებების გარეშე.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"შენი დავალებაა შექმნა ვიკიპედიის სტილის სტატია მოცემულ თემაზე ქართულ ენაზე. \\\n",
    "სტატია უნდა იყოს მოკლე, მაგრამ ინფორმაციული და დაწერილი ვიკიპედიის სტილში, რათა შესაძლებელი იყოს მისი დამატება ქართულ ვიკიპედიაში.\n",
    "\n",
    "სტატიის სათაური:\n",
    "<სათაური>\n",
    "{article_name}\n",
    "</სათაური>\n",
    "\n",
    "<სტატია>\n",
    "ჩაწერე შენი ვიკიპედიის სტილის სტატია აქ.\n",
    "</სტატია>\n",
    "\n",
    "გაითვალისწინე, რომ სტატია უნდა იყოს დაახლოებით 200-500 სიტყვა. ეცადე, რომ სტატია იყოს ობიექტური და არ შეიცავდეს პირად მოსაზრებებს.\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9c6d63-e915-43c3-b1b3-68922920c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_haiku(user_prompt):\n",
    "    \"\"\"\n",
    "    Claude-3-Haiku მოდელისგან ტექსტის მიღების ფუნქცია.\n",
    "\n",
    "    Args:\n",
    "        user_prompt (str): მომხმარებლის მიერ შეყვანილი ტექსტი/კითხვა.\n",
    "\n",
    "    Returns:\n",
    "        str: Claude-ის მიერ დაგენერირებული პასუხი.\n",
    "    \"\"\"\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=2048, # მაქსიმალური ტოკენების რაოდენობა რასაც ერთ გამოძახებაზე API-სგან მივიღებთ\n",
    "        temperature=0.6, # პარამეტრი რომელიც არეგულირებს პასუხების \"მრავალფეროვნებას\": მაღალი temperature -> მრავალფეროვანი ტექსტი\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": user_prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d9657e-c9c1-4ef2-8186-c61363bcb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ახლა შეგვიძლია დავაგენერიროთ ახალი სტატია:\n",
    "# ინგლისური სტატიის ლინკი: https://en.wikipedia.org/wiki/Large_language_model (ქართულ ენაზე სტატია არ არის ხელმისაწვდომი)\n",
    "article_name = \"დიდი ენობრივი მოდელები\"\n",
    "\n",
    "prompt = get_user_prompt(article_name)\n",
    "message = get_text_from_haiku(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce6e70c-61fc-4452-831b-11ea97558d70",
   "metadata": {},
   "source": [
    "#### დავაგენერიროთ 10 ახალი სტატია"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1f76df-42a8-4f4f-85e4-60eb479f9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# განვსაზღვროთ სტატიის სია (სახელები), რომლებზეც გვსურს ახალი სტატიის დაგენერირება\n",
    "article_names = [\n",
    "    \"ჩატჯიპიტი (ChatGPT)\", \"2023 წლის კრიკეტის მსოფლიო თასი\", \"ოპენჰაიმერი\", \"ჯავანი (ფილმი)\", \"ბარბი (ფილმი)\",\n",
    "    \"ტეილორ სვიფტი\", \"ელონ მასკი\", \"ავატარი\", \"ლიონელ მესი\", \"პრემიერ ლიგა\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95a5a798-8723-40e4-b3b5-c7587e286ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# განვსაზღვროთ დირექტორია სადაც შევინახავთ დაგენერირებულ მონაცემებს\n",
    "output_directory = \"wiki_synthetic/\"\n",
    "\n",
    "# დავრწმუნდით, რომ დირექტორია არსებობს\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92649b-8c44-4416-a323-6c030c99c9eb",
   "metadata": {},
   "source": [
    "ახლა კი შეგვიძლია დავაგენერიროთ მონაცემები:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39a6752a-d5f5-4ab6-9fac-1a4338eae5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# გაიარეთ თითოეული სტატიის სახელზე და დაამუშავეთ მოთხოვნა\n",
    "for article_name in article_names:\n",
    "    # მიიღეთ მომხმარებლის მოთხოვნა სტატიის სახელზე დაფუძნებით\n",
    "    prompt = get_user_prompt(article_name)\n",
    "    \n",
    "    # მიიღეთ ტექსტი Haiku API-დან\n",
    "    message = get_text_from_haiku(prompt)\n",
    "    \n",
    "    # მოამზადეთ მონაცემები JSON ფორმატში შესანახად\n",
    "    data = {\n",
    "        \"article_name\": article_name,  # სტატიის სახელი\n",
    "        \"prompt\": prompt,  # მომხმარებლის მოთხოვნა\n",
    "        \"generated_text\": message.content[0].text,  # გენერირებული ტექსტი\n",
    "        \"input_tokens\": message.usage.input_tokens,  # შეყვანილი ტოკენების რაოდენობა\n",
    "        \"output_tokens\": message.usage.output_tokens  # გენერირებული ტოკენების რაოდენობა\n",
    "    }\n",
    "    \n",
    "    # განსაზღვრა ფაილის ბილიკი\n",
    "    output_file_path = os.path.join(output_directory, f\"{article_name.replace(' ', '_')}.json\")\n",
    "    \n",
    "    # შეინახეთ მონაცემები JSON ფაილში\n",
    "    with open(output_file_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34759e31-ff4e-412b-9a17-1003c4aeea87",
   "metadata": {},
   "source": [
    "#### დაგენერირებული მონაცემების დამუშავება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce7cf840-226b-4a00-88f3-e91426e2c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023 Cricket World Cup</td>\n",
       "      <td>შენი დავალებაა შექმნა ვიკიპედიის სტილის სტატია...</td>\n",
       "      <td>&lt;სტატია&gt;\\n2023 Cricket World Cup\\n\\n2023 Crick...</td>\n",
       "      <td>313</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>შენი დავალებაა შექმნა ვიკიპედიის სტილის სტატია...</td>\n",
       "      <td>&lt;სტატია&gt;\\nავატარი (ინგლ. Avatar) არის მხატვრულ...</td>\n",
       "      <td>308</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_name                                             prompt  \\\n",
       "0  2023 Cricket World Cup  შენი დავალებაა შექმნა ვიკიპედიის სტილის სტატია...   \n",
       "1                  Avatar  შენი დავალებაა შექმნა ვიკიპედიის სტილის სტატია...   \n",
       "\n",
       "                                      generated_text  input_tokens  \\\n",
       "0  <სტატია>\\n2023 Cricket World Cup\\n\\n2023 Crick...           313   \n",
       "1  <სტატია>\\nავატარი (ინგლ. Avatar) არის მხატვრულ...           308   \n",
       "\n",
       "   output_tokens  \n",
       "0            702  \n",
       "1            591  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# შეაგროვეთ ყველა JSON ფაილის ბილიკი დირექტორიიდან\n",
    "json_files = [os.path.join(output_directory, file) for file in os.listdir(output_directory) if file.endswith('.json')]\n",
    "\n",
    "# ცარიელი სიის შექმნა მონაცემების შესაგროვებლად\n",
    "data_list = []\n",
    "\n",
    "# გაიარეთ თითოეულ JSON ფაილზე და წაიკითხეთ მონაცემები\n",
    "for json_file in json_files:\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        data_list.append(data)\n",
    "\n",
    "# მონაცემების ჩატვირთვა DataFrame-ში\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361ffc9-5909-4822-821a-070841b2a341",
   "metadata": {},
   "source": [
    "ახლა უკვე შეგვიძლია მონაცემები დავამუშავოთ (მოვაცილოთ ზედმეტი ტექსტი დაგენერურებულ სტატიებს)\n",
    "\n",
    "* შენიშვნა: LLM-ის პრომპტში გამოვიყენეთ <სტატია> ტეგები, რათა გამარტივდეს გენერირებული ტექსტის (ჩვენთვის საინტერესო ნაწილის) მოდელის პასუხიდან გამოყოფა. ეს საშუალებას გვაძლევს ადვილად ამოვიღოთ რელევანტური ტექსტი მოდელის პასუხიდან."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e95566a0-869d-49ab-bbfa-83bc62c52445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023 Cricket World Cup</td>\n",
       "      <td>შენი დავალებაა შექმნა ვიკიპედიის სტილის სტატია...</td>\n",
       "      <td>&lt;სტატია&gt;\\n2023 Cricket World Cup\\n\\n2023 Crick...</td>\n",
       "      <td>313</td>\n",
       "      <td>702</td>\n",
       "      <td>2023 Cricket World Cup\\n\\n2023 Cricket World C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>შენი დავალებაა შექმნა ვიკიპედიის სტილის სტატია...</td>\n",
       "      <td>&lt;სტატია&gt;\\nავატარი (ინგლ. Avatar) არის მხატვრულ...</td>\n",
       "      <td>308</td>\n",
       "      <td>591</td>\n",
       "      <td>ავატარი (ინგლ. Avatar) არის მხატვრული ფილმი, რ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             article_name                                             prompt  \\\n",
       "0  2023 Cricket World Cup  შენი დავალებაა შექმნა ვიკიპედიის სტილის სტატია...   \n",
       "1                  Avatar  შენი დავალებაა შექმნა ვიკიპედიის სტილის სტატია...   \n",
       "\n",
       "                                      generated_text  input_tokens  \\\n",
       "0  <სტატია>\\n2023 Cricket World Cup\\n\\n2023 Crick...           313   \n",
       "1  <სტატია>\\nავატარი (ინგლ. Avatar) არის მხატვრულ...           308   \n",
       "\n",
       "   output_tokens                                       cleaned_text  \n",
       "0            702  2023 Cricket World Cup\\n\\n2023 Cricket World C...  \n",
       "1            591  ავატარი (ინგლ. Avatar) არის მხატვრული ფილმი, რ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ფუნქცია, რომელიც ამოწმებს \"<სტატია>\" ტეგებს შორის ტექსტს და სტრიპინგს\n",
    "def extract_text_between_tags(text):\n",
    "    match = re.search(r'<სტატია>(.*?)<\\/სტატია>', text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "# აქ ატვირთეთ DataFrame, მაგალითად, df\n",
    "# df = pd.read_csv('path/to/your/dataframe.csv') # თუ csv ფაილია\n",
    "\n",
    "# წინა კოდიდან მიღებული DataFrame გამოიყენეთ\n",
    "# DataFrame-ის სვეტი, რომელიც \"generated_text\"-ს შეიცავს\n",
    "df['cleaned_text'] = df['generated_text'].apply(extract_text_between_tags)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3cfc5c",
   "metadata": {},
   "source": [
    "ახლა კი უკვე შეგვიძლია შევამოწმოთ დაგენერირებული ტექსტი:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "832dfe95-237c-4e0e-a037-d4660333c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "სათაური: 2023 Cricket World Cup\n",
      "2023 Cricket World Cup\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ტექსტი:\n",
      "2023 Cricket World Cup\n",
      "\n",
      "2023 Cricket World Cup იქნება მსოფლიოს 13-ე კრიკეტის მსოფლიო თასი, რომელიც ჩატარდება ინდოეთში 2023 წლის 9 ოქტომბრიდან 26 ნოემბრამდე. ეს იქნება პირველი მსოფლიო თასი, რომელიც ჩატარდება ინდოეთში.\n",
      "\n",
      "ტურნირში მონაწილეობას მიიღებს 10 გუნდი, რომლებიც მოხვდებიან ჯგუფურ ეტაპზე და შემდგომ გამოავლენენ ოთხეულს, რომლებიც გადავლენ ნოკ-აუთ სტადიაზე. ფინალი გაიმართება 26 ნოემბერს.\n",
      "\n",
      "ინდოეთი იქნება ერთ-ერთი მასპინძელი ქვეყანა, თუმცა სავარაუდოდ, ტურნირის მეორე ნაწილი ჩატარდება სხვა ქვეყნებშიც, რომლებიც ჯერ კიდევ უნდა დადგინდეს.\n",
      "\n",
      "2023 წლის მსოფლიო თასი იქნება პირველი, რომელშიც მონაწილეობას არ მიიღებენ ზიმბაბვე და ავღანეთის ეროვნული ნაკრებები. ეს გადაწყვეტილება მიღებულ იქნა ICC-ის მიერ, რომელმაც მიიჩნია, რომ ეს ორი ქვეყანა ვერ აკმაყოფილებს საჭირო კრიტერიუმებს.\n",
      "\n",
      "მოსალოდნელია, რომ 2023 წლის მსოფლიო თასი იქნება ერთ-ერთი ყველაზე მასშტაბური და მნიშვნელოვანი კრიკეტის ტურნირი, რომელშიც მონაწილეობას მიიღებენ მსოფლიოს წამყვანი გუნდები.\n"
     ]
    }
   ],
   "source": [
    "# ვიღებთ პირველ მაგალითს წინა Dataframe-ში\n",
    "example = df.iloc[0]\n",
    "\n",
    "# ვბეჭდავთ სათაურს და ტექსტს\n",
    "print(\"სათაური:\", example['article_name'])\n",
    "print(example['article_name'])\n",
    "print(\"---\"*40)\n",
    "print(\"ტექსტი:\")\n",
    "print(example['cleaned_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

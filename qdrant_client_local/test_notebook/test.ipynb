{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **წრფივი რეგრესია**\n",
        "წრფივი რეგრესია არის სტატისტიკური მეთოდი, რომელიც გამოიყენება დამოკიდებულ ცვლადსა (y) და ერთ ან მეტ დამოუკიდებელ ცვლადს (x) შორის წრფივი ურთიერთობის მოდელირებისთვის. მისი მიზანია იპოვოს საუკეთესო წრფივი ფუნქცია, რომელიც აღწერს ამ ურთიერთობას.\n",
        "მათემატიკურად, მარტივი წრფივი რეგრესია შეიძლება გამოისახოს შემდეგნაირად:\n",
        "\n",
        "y = βₒ + β₁x + ε\n",
        "\n",
        "სადაც:\n",
        "\n",
        "y არის დამოკიდებული ცვლადი\n",
        "\n",
        "*   x არის დამოუკიდებელი ცვლადი\n",
        "\n",
        "*   βₒ არის y-ღერძთან გადაკვეთის წერტილი\n",
        "\n",
        "*   β₁ არის დახრილობა\n",
        "\n",
        "*   ε არის შემთხვევითი შეცდომა\n"
      ],
      "metadata": {
        "id": "MBn2UD36e7lL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq70rXhve3Et"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# შემთხვევითი\n",
        "np.random.seed(42)\n",
        "\n",
        "# მაგალითი წერტილების შექმნა\n",
        "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\n",
        "y = 2 * X + 1 + np.random.randn(10, 1) * 2\n",
        "\n",
        "# გრაფიკი მორგების გარეშე\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(121)\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.title('მონაცემთა წერტილები მორგების გარეშე')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "\n",
        "# წრფივი რეგრესიის მოდელის შექმნა და მორგება\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# პროგნოზირება\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# გრაფიკი მორგებით\n",
        "plt.subplot(122)\n",
        "plt.scatter(X, y, color='blue', label='რეალური მონაცემები')\n",
        "plt.plot(X, y_pred, color='red', label='მორგებული ხაზი')\n",
        "plt.title('წრფივი რეგრესია მორგებით')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# მოდელის პარამეტრების ჩვენება\n",
        "print(f\"დახრილობა (β₁): {model.coef_[0][0]:.2f}\")\n",
        "print(f\"y-გადაკვეთა (βₒ): {model.intercept_[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ეს მაგალითი გვიჩვენებს, თუ როგორ მუშაობს წრფივი რეგრესია პრაქტიკაში. მორგებული ხაზი ცდილობს საუკეთესოდ წარმოადგინოს ზოგადი ტენდენცია მონაცემებში, მინიმუმამდე დაიყვანოს საშუალო კვადრატული ცდომილება ყველა წერტილისთვის.\n",
        "\n",
        "ზემოთ კოდში:\n",
        "\n",
        "\n",
        "*  პირველ რიგში, ჩვენ ვქმნით მაგალითის მონაცემებს. X არის 1-დან 10-მდე მნიშვნელობები, ხოლო y არის გამოთვლილი ფორმულით y = 2X + 1, დამატებული შემთხვევითი ხმაური.\n",
        "\n",
        "*  პირველი გრაფიკი (\"მონაცემთა წერტილები მორგების გარეშე\") უბრალოდ აჩვენებს გაფანტულ წერტილებს მორგებული ხაზის გარეშე.\n",
        "შემდეგ ჩვენ ვიყენებთ sklearn-ის LinearRegression კლასს მოდელის შესაქმნელად და მოსარგებად.\n",
        "\n",
        "*  მეორე გრაფიკი (\"წრფივი რეგრესია მორგებით\") აჩვენებს იგივე გაფანტულ წერტილებს, მაგრამ ამჯერად წითელი ხაზით, რომელიც წარმოადგენს მორგებულ წრფივ მოდელს.\n",
        "\n",
        "*  ბოლოს, ჩვენ ვბეჭდავთ მოდელის პარამეტრებს - დახრილობას (β₁) და y-გადაკვეთას (βₒ)."
      ],
      "metadata": {
        "id": "zHaVsZXFiYB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# პარამეტრები\n",
        "წრფივი რეგრესიის მოდელში პარამეტრები არის βₒ (ინტერცეპტი) და β₁ (დახრილობა). ეს პარამეტრები განსაზღვრავენ წრფის პოზიციას და ორიენტაციას მონაცემთა წერტილებთან მიმართებაში.\n",
        "\n",
        "βₒ (ინტერცეპტი): ეს არის წერტილი, სადაც რეგრესიის ხაზი კვეთს y-ღერძს (როდესაც x = 0).\n",
        "\n",
        "β₁ (დახრილობა): ეს გვიჩვენებს, თუ რამდენით იცვლება y, როდესაც x იცვლება ერთი ერთეულით.\n",
        "\n",
        "# დანაკარგის ფუნქცია\n",
        "\n",
        "დანაკარგის ფუნქცია არის მეთოდი, რომელიც გამოიყენება მოდელის პროგნოზებსა და რეალურ მნიშვნელობებს შორის განსხვავების გასაზომად. წრფივი რეგრესიისთვის ყველაზე ხშირად გამოიყენება საშუალო კვადრატული ცდომილება (Mean Squared Error - MSE).\n",
        "MSE განისაზღვრება შემდეგნაირად:\n",
        "MSE = (1/n) Σ(yᵢ - ŷᵢ)²\n",
        "სადაც:\n",
        "\n",
        "n არის დაკვირვებების რაოდენობა\n",
        "yᵢ არის რეალური მნიშვნელობა\n",
        "ŷᵢ არის პროგნოზირებული მნიშვნელობა\n",
        "\n",
        "მოდით, შევქმნათ ფუნქცია MSE-ს გამოსათვლელად და გრაფიკულად გამოვსახოთ ის:"
      ],
      "metadata": {
        "id": "XiOeYpBejCdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred)**2)\n",
        "\n",
        "# მონაცემების გენერირება\n",
        "np.random.seed(0)\n",
        "X = np.linspace(0, 10, 100).reshape(-1, 1)\n",
        "y = 2 * X + 1 + np.random.randn(100, 1)\n",
        "\n",
        "# მოდელის მორგება\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# პროგნოზირება\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# MSE-ს გამოთვლა\n",
        "mse_value = mse(y, y_pred)\n",
        "\n",
        "# გრაფიკის დახაზვა\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', label='რეალური მონაცემები')\n",
        "plt.plot(X, y_pred, color='red', label='პროგნოზირებული ხაზი')\n",
        "plt.title(f'წრფივი რეგრესია (MSE = {mse_value:.2f})')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R0mi4q0giFfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE ყოველთვის არაუარყოფითია. რაც უფრო ახლოსაა ის ნულთან, მით უკეთესია მოდელი.\n",
        "ის მგრძნობიარეა დიდი შეცდომების მიმართ, რადგან ის აკვადრატებს შეცდომებს."
      ],
      "metadata": {
        "id": "Sn2P0k1ej1qS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# მორგება (Fitting)\n",
        "მორგება არის პროცესი, როდესაც ვპოულობთ საუკეთესო პარამეტრებს (βₒ და β₁) ჩვენი მოდელისთვის. ეს ხშირად კეთდება უმცირესი კვადრატების მეთოდით, რომელიც ცდილობს მინიმუმამდე დაიყვანოს MSE.\n",
        "მათემატიკურად, უმცირესი კვადრატების შემფასებლები მოიცემა შემდეგნაირად:\n",
        "β₁ = Σ((xᵢ - x̄)(yᵢ - ȳ)) / Σ((xᵢ - x̄)²)\n",
        "βₒ = ȳ - β₁x̄\n",
        "სადაც x̄ და ȳ არის X-ისა და y-ის საშუალო მნიშვნელობები შესაბამისად."
      ],
      "metadata": {
        "id": "eT6AbHRUkBtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# R-კვადრატი (R-squared)\n",
        "R-კვადრატი, ასევე ცნობილი როგორც დეტერმინაციის კოეფიციენტი, არის სტატისტიკური საზომი, რომელიც გვიჩვენებს, თუ რამდენად კარგად ერგება მოდელი მონაცემებს.\n",
        "R² = 1 - (Σ(yᵢ - ŷᵢ)² / Σ(yᵢ - ȳ)²)\n",
        "სადაც ȳ არის y-ის საშუალო მნიშვნელობა.\n",
        "მნიშვნელობა:\n",
        "\n",
        "* R² მერყეობს 0-დან 1-მდე.\n",
        "* R² = 1 ნიშნავს იდეალურ მორგებას.\n",
        "* R² = 0 ნიშნავს, რომ მოდელი არ არის უკეთესი, ვიდრე უბრალოდ y-ის საშუალო მნიშვნელობის გამოყენება.\n",
        "\n",
        "მოდით, გამოვთვალოთ და გრაფიკულად გამოვსახოთ R-კვადრატი:"
      ],
      "metadata": {
        "id": "RARKBkKgkOB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', label='რეალური მონაცემები')\n",
        "plt.plot(X, y_pred, color='red', label='პროგნოზირებული ხაზი')\n",
        "plt.title(f'წრფივი რეგრესია (R² = {r2:.2f})')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tWFtPMa0jiOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "სტატისტიკური თვალსაზრისით, წრფივი რეგრესია ეფუძნება რამდენიმე ძირითად დაშვებას:\n",
        "\n",
        "წრფივობა: დამოკიდებულ და დამოუკიდებელ ცვლადებს შორის არსებობს წრფივი ურთიერთობა.\n",
        "\n",
        "დამოუკიდებლობა: დაკვირვებები დამოუკიდებელია ერთმანეთისგან.\n",
        "\n",
        "ჰომოსკედასტურობა: (yᵢ - ŷᵢ) - ამ სხვაობის ვარიაცია მუდმივია ყველა დამოუკიდებელი ცვლადის მნიშვნელობისთვის.\n",
        "\n",
        "ნორმალურობა: (yᵢ - ŷᵢ) ეს სხვაობები ნორმალურად არის განაწილებული.\n",
        "\n",
        "ეს დაშვებები მნიშვნელოვანია მოდელის ვალიდურობისა და შედეგების ინტერპრეტაციისთვის.\n",
        "\n",
        "მოდით, შევამოწმოთ ზოგიერთი ეს დაშვება ჩვენი მოდელისთვის:"
      ],
      "metadata": {
        "id": "wk5fno3ckyir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y - y_pred\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# ნარჩენების გრაფიკი\n",
        "plt.subplot(121)\n",
        "plt.scatter(y_pred, residuals)\n",
        "plt.xlabel('პროგნოზირებული მნიშვნელობები')\n",
        "plt.ylabel('ნარჩენები')\n",
        "plt.title('ნარჩენების გრაფიკი')\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "\n",
        "# ნარჩენების ჰისტოგრამა\n",
        "plt.subplot(122)\n",
        "plt.hist(residuals, bins=20)\n",
        "plt.xlabel('ნარჩენები')\n",
        "plt.ylabel('სიხშირე')\n",
        "plt.title('ნარჩენების ჰისტოგრამა')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H7NOJjbzkbxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "წრფივი რეგრესია არის მძლავრი სტატისტიკური ინსტრუმენტი, რომელიც გვეხმარება გავიგოთ და გავაანალიზოთ ურთიერთობა ცვლადებს შორის. ის გვაძლევს საშუალებას გავაკეთოთ პროგნოზები და შევაფასოთ მოდელის ეფექტურობა სხვადასხვა მეტრიკის გამოყენებით, როგორიცაა MSE და R-კვადრატი. თუმცა, მნიშვნელოვანია გვახსოვდეს მისი ძირითადი დაშვებები და შეზღუდვები რეალურ სამყაროში გამოყენებისას."
      ],
      "metadata": {
        "id": "T_bZTLUdlzDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# მრავალცვლადიანი წრფივი რეგრესია\n",
        "მრავალცვლადიანი წრფივი რეგრესია არის წრფივი რეგრესიის გაფართოება, რომელიც საშუალებას გვაძლევს გამოვიყენოთ ერთზე მეტი დამოუკიდებელი ცვლადი (პრედიქტორი) დამოკიდებული ცვლადის პროგნოზირებისთვის. ეს მეთოდი გვეხმარება უფრო რთული ურთიერთობების მოდელირებაში რეალურ სამყაროში, სადაც ხშირად ერთზე მეტი ფაქტორი გავლენას ახდენს შედეგზე.\n",
        "მრავალცვლადიანი წრფივი რეგრესიის მათემატიკური მოდელი:\n",
        "y = βₒ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε\n",
        "სადაც:\n",
        "\n",
        "\n",
        "y არის დამოკიდებული ცვლადი\n",
        "\n",
        "x₁, x₂, ..., xₙ არიან დამოუკიდებელი ცვლადები\n",
        "βₒ არის y-გადაკვეთა\n",
        "\n",
        "β₁, β₂, ..., βₙ არიან შესაბამისი კოეფიციენტები (დახრილობები) თითოეული დამოუკიდებელი ცვლადისთვის\n",
        "\n",
        "ε არის შემთხვევითი შეცდომა\n",
        "\n",
        "მოდით, შევქმნათ მაგალითი მრავალცვლადიანი წრფივი რეგრესიისთვის და ვიზუალიზაცია გავუკეთოთ შედეგებს:"
      ],
      "metadata": {
        "id": "7g-IXXDDmQrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# შემთხვევითი თესლის დაყენება\n",
        "np.random.seed(42)\n",
        "\n",
        "# მონაცემების გენერირება\n",
        "n_samples = 100\n",
        "X = np.random.rand(n_samples, 2) * 10\n",
        "y = 2 * X[:, 0] + 3 * X[:, 1] + 1 + np.random.randn(n_samples) * 2\n",
        "\n",
        "# მოდელის შექმნა და მორგება\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# პროგნოზირება\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# 3D გრაფიკის შექმნა\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# მონაცემთა წერტილების დახაზვა\n",
        "ax.scatter(X[:, 0], X[:, 1], y, c='blue', label='რეალური მონაცემები')\n",
        "\n",
        "# პროგნოზირებული სიბრტყის დახაზვა\n",
        "x1_surf, x2_surf = np.meshgrid(np.linspace(0, 10, 100), np.linspace(0, 10, 100))\n",
        "y_surf = model.intercept_ + model.coef_[0] * x1_surf + model.coef_[1] * x2_surf\n",
        "ax.plot_surface(x1_surf, x2_surf, y_surf, alpha=0.3, color='red')\n",
        "\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_zlabel('y')\n",
        "ax.legend()\n",
        "plt.title('მრავალცვლადიანი წრფივი რეგრესია')\n",
        "plt.show()\n",
        "\n",
        "# მოდელის პარამეტრების ჩვენება\n",
        "print(f\"y-გადაკვეთა (βₒ): {model.intercept_:.2f}\")\n",
        "print(f\"X1-ის კოეფიციენტი (β₁): {model.coef_[0]:.2f}\")\n",
        "print(f\"X2-ის კოეფიციენტი (β₂): {model.coef_[1]:.2f}\")"
      ],
      "metadata": {
        "id": "uKcN2Xv_kjZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ამ მაგალითში:\n",
        "\n",
        "ჩვენ ვქმნით ორ დამოუკიდებელ ცვლადს (X1 და X2) და ერთ დამოკიდებულ ცვლადს (y).\n",
        "\n",
        "y გამოითვლება ფორმულით: y = 2X1 + 3X2 + 1 + შემთხვევითი ხმაური.\n",
        "\n",
        "ვიყენებთ sklearn-ის LinearRegression კლასს მოდელის შესაქმნელად და მოსარგებად.\n",
        "\n",
        "ვქმნით 3D გრაფიკს, სადაც:\n",
        "\n",
        "* ლურჯი წერტილები წარმოადგენს რეალურ მონაცემებს\n",
        "* წითელი სიბრტყე წარმოადგენს მორგებულ მოდელს\n",
        "\n",
        "\n",
        "ვბეჭდავთ მოდელის პარამეტრებს (y-გადაკვეთას და თითოეული ცვლადის კოეფიციენტს).\n",
        "\n",
        "\n",
        "**მრავალცვლადიანი წრფივი რეგრესიის უპირატესობები:**\n",
        "\n",
        "კომპლექსურობა: საშუალებას გვაძლევს მოვახდინოთ უფრო რთული ურთიერთობების მოდელირება.\n",
        "\n",
        "პროგნოზის სიზუსტე: ხშირად უზრუნველყოფს უფრო ზუსტ პროგნოზებს, ვიდრე მარტივი წრფივი რეგრესია.\n",
        "\n",
        "ცვლადების მნიშვნელობის შეფასება: გვეხმარება გავიგოთ, თუ რომელი ცვლადები ახდენენ ყველაზე დიდ გავლენას შედეგზე.\n",
        "\n",
        "**გამოწვევები და გასათვალისწინებელი საკითხები:**\n",
        "\n",
        "მულტიკოლინეარობა: როდესაც დამოუკიდებელი ცვლადები ძლიერ კორელირებულია ერთმანეთთან, ეს შეიძლება პრობლემური იყოს მოდელისთვის.\n",
        "\n",
        "ინტერპრეტაცია: მეტი ცვლადის დამატებით, მოდელის ინტერპრეტაცია შეიძლება უფრო რთული გახდეს.\n",
        "\n",
        "გადაჭარბებული მორგება: ძალიან ბევრი ცვლადის გამოყენებამ შეიძლება გამოიწვიოს გადაჭარბებული მორგება, განსაკუთრებით მცირე მონაცემთა ნაკრებებისთვის.\n",
        "\n",
        "\n",
        "მრავალცვლადიანი წრფივი რეგრესია არის მძლავრი ინსტრუმენტი, რომელიც ფართოდ გამოიყენება სხვადასხვა სფეროში, მათ შორის ეკონომიკაში, სოციალურ მეცნიერებებში, ბიოლოგიაში და ინჟინერიაში."
      ],
      "metadata": {
        "id": "GOryXLBCmsrD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "od6dp32zmgTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}